{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:04:48.055092Z",
     "start_time": "2018-08-26T16:04:43.052Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/local/bin/python3\n",
    "import os\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy import interp\n",
    "from drivendata_validator import DrivenDataValidator\n",
    "from tpot import TPOTRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc, log_loss, mean_absolute_error, make_scorer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:04:48.058370Z",
     "start_time": "2018-08-26T16:04:43.057Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def pre_process_train_test_data(train, test, label_var, exclude_scaling):\n",
    "    labels = np.ravel(train[label_var])\n",
    "    train = pd.get_dummies(train.drop(label_var, axis=1))\n",
    "    test = pd.get_dummies(test)\n",
    "\n",
    "    # match test set and training set columns\n",
    "    to_drop = np.setdiff1d(test.columns, train.columns)\n",
    "    to_add = np.setdiff1d(train.columns, test.columns)\n",
    "\n",
    "    test.drop(to_drop, axis=1, inplace=True)\n",
    "    test = test.assign(**{c: 0 for c in to_add})\n",
    "\n",
    "    test_indices = test.index\n",
    "    train_indices = train.index\n",
    "    train_test = pd.concat([train, test])\n",
    "    train_test.sort_values(['year', 'weekofyear'], inplace=True)\n",
    "    train_test.interpolate(method='linear', inplace=True)\n",
    "\n",
    "    print(\"Shapes before transformation\")\n",
    "    print(\"Train : \", train.shape)\n",
    "    print(\"Test : \", test.shape)\n",
    "    print(\"Train + Test : \", train_test.shape)\n",
    "\n",
    "    numeric_vals = train_test.select_dtypes(include=['int64', 'float64'])\n",
    "    numeric_vals = numeric_vals.loc[:, [x for x in list(numeric_vals.columns.values) if x not in exclude_scaling]]\n",
    "    scaler = StandardScaler()\n",
    "    train_test[numeric_vals.columns] = scaler.fit_transform(numeric_vals)\n",
    "\n",
    "    train = train_test.loc[train_indices, :]\n",
    "    test = train_test.loc[test_indices, :]\n",
    "\n",
    "    train[label_var] = labels\n",
    "\n",
    "    print(\"Shapes after transformation\")\n",
    "    print(\"Train : \", train.shape)\n",
    "    print(\"Test : \",  test.shape)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:04:48.061693Z",
     "start_time": "2018-08-26T16:04:43.064Z"
    }
   },
   "outputs": [],
   "source": [
    "## define data paths\n",
    "DATA_DIR = '../data'\n",
    "data_paths = {'train_x': os.path.join(DATA_DIR, 'dengue_features_train.csv'),\n",
    "              'train_y': os.path.join(DATA_DIR, 'dengue_labels_train.csv'),\n",
    "               'test_x':  os.path.join(DATA_DIR, 'dengue_features_test.csv')}\n",
    "\n",
    "## load training data\n",
    "X_train = pd.read_csv(data_paths['train_x'])\n",
    "y_train = pd.read_csv(data_paths['train_y'])\n",
    "X_train.drop(columns='week_start_date', inplace=True)\n",
    "\n",
    "## load test data\n",
    "X_test = pd.read_csv(data_paths['test_x'])\n",
    "X_test.drop(columns='week_start_date', inplace=True)\n",
    "\n",
    "## Pre-process Data\n",
    "print(\"Shapes before transformation\")\n",
    "print(\"Train : \", X_train.shape)\n",
    "print(\"Train Labels : \", y_train.shape)\n",
    "print(\"Test : \", X_test.shape)\n",
    "print(\"Columns : \", X_train.columns)\n",
    "train_data = pd.merge(X_train, y_train, on=['city', 'year', 'weekofyear'])\n",
    "train_data.index = np.arange(0, train_data.shape[0])\n",
    "X_test.index = np.arange(train_data.shape[0]+1, train_data.shape[0]+X_test.shape[0]+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:04:48.063913Z",
     "start_time": "2018-08-26T16:04:43.071Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_data.rename(columns={'precipitation_amt_mm': 'sat_precip', \n",
    "                        'reanalysis_air_temp_k': 'pred_temp',\n",
    "                        'reanalysis_avg_temp_k': 'pred_avg_temp',\n",
    "                        'reanalysis_dew_point_temp_k': 'pred_dew_temp',\n",
    "                        'reanalysis_max_air_temp_k': 'pred_max_temp',\n",
    "                        'reanalysis_min_air_temp_k': 'pred_min_temp',\n",
    "                        'reanalysis_precip_amt_kg_per_m2': 'pred_precip_vol',\n",
    "                        'reanalysis_specific_humidity_g_per_kg' : 'pred_spec_humidity',\n",
    "                        'reanalysis_tdtr_k' : 'pred_temp_rng',\n",
    "                        'reanalysis_relative_humidity_percent' : 'pred_rel_humidity_per',\n",
    "                        'reanalysis_sat_precip_amt_mm': 'pred_sat_precip'\n",
    "                        })\n",
    "train_data.interpolate(method='linear', inplace=True)\n",
    "\n",
    "X_test = X_test.rename(columns={'precipitation_amt_mm': 'pred_precip', \n",
    "                        'reanalysis_air_temp_k': 'pred_temp',\n",
    "                        'reanalysis_avg_temp_k': 'pred_avg_temp',\n",
    "                        'reanalysis_dew_point_temp_k': 'pred_dew_temp',\n",
    "                        'reanalysis_max_air_temp_k': 'pred_max_temp',\n",
    "                        'reanalysis_min_air_temp_k': 'pred_min_temp',\n",
    "                        'reanalysis_precip_amt_kg_per_m2': 'pred_precip_vol',\n",
    "                        'reanalysis_specific_humidity_g_per_kg' : 'pred_spec_humidity',\n",
    "                        'reanalysis_tdtr_k' : 'pred_temp_rng',\n",
    "                        'reanalysis_relative_humidity_percent' : 'pred_rel_humidity_per',\n",
    "                        'reanalysis_sat_precip_amt_mm': 'pred_sat_precip'\n",
    "                        })\n",
    "X_test.interpolate(method='linear', inplace=True)\n",
    "\n",
    "kelvin_cols = ['pred_temp', 'pred_avg_temp', 'pred_dew_temp', 'pred_max_temp', 'pred_min_temp']\n",
    "train_data.loc[:, kelvin_cols] = train_data.loc[:, kelvin_cols].copy() - 273.15\n",
    "X_test.loc[:, kelvin_cols] = X_test.loc[:, kelvin_cols].copy() - 273.15\n",
    "\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:04:48.068273Z",
     "start_time": "2018-08-26T16:04:43.075Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:04:48.072213Z",
     "start_time": "2018-08-26T16:04:43.078Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_cols = ['pred_precip', ] \n",
    "sat_cols = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:04:48.073608Z",
     "start_time": "2018-08-26T16:04:43.083Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.loc[:, ['pred_avg_temp', 'station_avg_temp_c']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:04:48.075433Z",
     "start_time": "2018-08-26T16:04:43.085Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check the type of our features. Are there any data inconsistencies?\n",
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:04:48.077426Z",
     "start_time": "2018-08-26T16:04:43.088Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the statistical overview of the employees\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:04:48.081966Z",
     "start_time": "2018-08-26T16:04:43.091Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a correlation matrix. What features correlate the most with turnover? What other correlations did you find?\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr = train_data.corr()\n",
    "corr = (corr)\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values, cmap=\"vlag\",)\n",
    "plt.title('Heatmap of Correlation Matrix')\n",
    "# corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:04:48.084566Z",
     "start_time": "2018-08-26T16:04:43.094Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.clustermap(corr, center=0, cmap=\"vlag\",\n",
    "               linewidths=.75, figsize=(13, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:04:48.093734Z",
     "start_time": "2018-08-26T16:04:43.100Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.pairplot(train_data, hue=\"total_cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:04:48.097319Z",
     "start_time": "2018-08-26T16:04:43.119Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Preprocessing Training\")\n",
    "# label_var = 'total_cases'\n",
    "# exclude_scaling = ['year', 'weekofyear']\n",
    "# a_train, a_test = pre_process_train_test_data(train_data, X_test, label_var, exclude_scaling)\n",
    "# X_train = a_train.drop(label_var, axis=1)\n",
    "# y_train = np.ravel(a_train[label_var])\n",
    "\n",
    "# ## restructure train data\n",
    "# all_train_data = {'features': X_train,\n",
    "#                   'labels': y_train}\n",
    "\n",
    "# ## restructure test data\n",
    "# all_test_data = {'features': a_test}\n",
    "\n",
    "# # ### Cross-validation -- Tune Parameters\n",
    "# X = all_train_data['features'].values.astype(np.float32)\n",
    "# y = all_train_data['labels'].astype(np.int16)\n",
    "# X_test = all_test_data['features'].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:04:48.099304Z",
     "start_time": "2018-08-26T16:04:43.122Z"
    }
   },
   "outputs": [],
   "source": [
    "# tune_params = 0\n",
    "# if tune_params > 0:\n",
    "#     bestParams = []\n",
    "#     X = all_train_data['features'].values.astype(np.float32)\n",
    "#     y = all_train_data['labels'].astype(np.int32)\n",
    "#     mae_score = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "#     pipeline_optimizer = TPOTRegressor(scoring=mae_score, cv=5,\n",
    "#                                         periodic_checkpoint_folder='tpot_best_models_100',\n",
    "#                                         n_jobs=2, random_state=42, verbosity=1, memory='auto',\n",
    "#                                         generations=100, max_eval_time_mins=10)\n",
    "#     pipeline_optimizer.fit(X, y)\n",
    "#     pipeline_optimizer.export('tpot_best_model_pipeline_gen_100_mae.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
