{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:49:05.839279Z",
     "start_time": "2018-08-25T22:49:01.348155Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaul\\Anaconda2\\envs\\py37\\lib\\site-packages\\sklearn\\utils\\__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n",
      "C:\\Users\\Shaul\\Anaconda2\\envs\\py37\\lib\\site-packages\\deap\\tools\\_hypervolume\\pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n",
      "C:\\Users\\Shaul\\Anaconda2\\envs\\py37\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Shaul\\Anaconda2\\envs\\py37\\lib\\importlib\\_bootstrap_external.py:434: ImportWarning: Not importing directory C:\\Users\\Shaul\\Anaconda2\\envs\\py37\\lib\\site-packages\\mpl_toolkits: missing __init__\n",
      "  _warnings.warn(msg.format(portions[0]), ImportWarning)\n",
      "C:\\Users\\Shaul\\Anaconda2\\envs\\py37\\lib\\importlib\\_bootstrap_external.py:434: ImportWarning: Not importing directory c:\\users\\shaul\\anaconda2\\envs\\py37\\lib\\site-packages\\mpl_toolkits: missing __init__\n",
      "  _warnings.warn(msg.format(portions[0]), ImportWarning)\n",
      "C:\\Users\\Shaul\\Anaconda2\\envs\\py37\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/local/bin/python3\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_curve, auc, log_loss\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy import interp\n",
    "#from drivendata_validator import DrivenDataValidator\n",
    "import itertools\n",
    "from tpot import TPOTClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# data directory\n",
    "DATA_DIR = os.path.join('..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:49:05.879843Z",
     "start_time": "2018-08-25T22:49:05.847393Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make Submission DataFrame\n",
    "def make_country_sub(preds, test_feat, country):\n",
    "    # make sure we code the country correctly\n",
    "    country_codes = ['A', 'B', 'C']\n",
    "    \n",
    "    # get just the poor probabilities\n",
    "    country_sub = pd.DataFrame(data=preds[:, 1],  # proba p=1\n",
    "                               columns=['poor'], \n",
    "                               index=test_feat.index)\n",
    "\n",
    "    \n",
    "    # add the country code for joining later\n",
    "    country_sub[\"country\"] = country\n",
    "    return country_sub[[\"country\", \"poor\"]]\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Household-level survey data: \n",
    "This is obfuscated data from surveys conducted by The World Bank, focusing on household-level statistics. The data come from three different countries, and are separated into different files for convenience.\n",
    "\n",
    "##### Individual-level survey data: \n",
    "This is obfuscated data from related surveys conducted by The World Bank, only these focus on individual-level statistics. The set of interviewees and countries involved are the same as the household data, as indicated by shared id indices, but this data includes detailed (obfuscated) information about household members.\n",
    "\n",
    "##### Submission format:\n",
    "This gives us the filenames and columns of our submission prediction, filled with all 0.5 as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:49:05.902762Z",
     "start_time": "2018-08-25T22:49:05.886140Z"
    }
   },
   "outputs": [],
   "source": [
    "## define data paths\n",
    "data_paths = {'train_x': os.path.join(DATA_DIR, 'dengue_features_train.csv'),\n",
    "              'train_y': os.path.join(DATA_DIR, 'dengue_labels_train.csv'),\n",
    "               'test_x':  os.path.join(DATA_DIR, 'dengue_features_test.csv')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:49:06.008189Z",
     "start_time": "2018-08-25T22:49:05.913794Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load training data\n",
    "X_train = pd.read_csv(data_paths['train_x'])\n",
    "y_train = pd.read_csv(data_paths['train_y'])\n",
    "X_train.drop(columns='week_start_date', inplace=True)\n",
    "\n",
    "# load test data\n",
    "X_test = pd.read_csv(data_paths['test_x'])\n",
    "X_test.drop(columns='week_start_date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first thing to notice is that each country's surveys have wildly different numbers of columns, so we'll plan on training separate models for each country and combining our predictions for submission at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:49:06.039686Z",
     "start_time": "2018-08-25T22:49:06.012773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes before transformation\n",
      "Train :  (1456, 23)\n",
      "Train Labels :  (1456, 4)\n",
      "Test :  (416, 23)\n",
      "Columns :  Index(['city', 'year', 'weekofyear', 'ndvi_ne', 'ndvi_nw', 'ndvi_se',\n",
      "       'ndvi_sw', 'precipitation_amt_mm', 'reanalysis_air_temp_k',\n",
      "       'reanalysis_avg_temp_k', 'reanalysis_dew_point_temp_k',\n",
      "       'reanalysis_max_air_temp_k', 'reanalysis_min_air_temp_k',\n",
      "       'reanalysis_precip_amt_kg_per_m2',\n",
      "       'reanalysis_relative_humidity_percent', 'reanalysis_sat_precip_amt_mm',\n",
      "       'reanalysis_specific_humidity_g_per_kg', 'reanalysis_tdtr_k',\n",
      "       'station_avg_temp_c', 'station_diur_temp_rng_c', 'station_max_temp_c',\n",
      "       'station_min_temp_c', 'station_precip_mm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes before transformation\")\n",
    "print(\"Train : \", X_train.shape)\n",
    "print(\"Train Labels : \", y_train.shape)\n",
    "print(\"Test : \", X_test.shape)\n",
    "print(\"Columns : \", X_train.columns)\n",
    "train_data = pd.merge(X_train, y_train, on=['city', 'year', 'weekofyear'])\n",
    "train_data.index = np.arange(0, train_data.shape[0])\n",
    "X_test.index = np.arange(train_data.shape[0]+1, train_data.shape[0]+X_test.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:49:06.082009Z",
     "start_time": "2018-08-25T22:49:06.047259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city           object\n",
       "year            int64\n",
       "weekofyear      int64\n",
       "total_cases     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:49:06.118240Z",
     "start_time": "2018-08-25T22:49:06.088361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,\n",
       "       2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:49:06.143947Z",
     "start_time": "2018-08-25T22:49:06.130945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sj', 'iq'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.city.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:49:06.279111Z",
     "start_time": "2018-08-25T22:49:06.149538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>reanalysis_avg_temp_k</th>\n",
       "      <th>...</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>18</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.198483</td>\n",
       "      <td>0.177617</td>\n",
       "      <td>12.42</td>\n",
       "      <td>297.572857</td>\n",
       "      <td>297.742857</td>\n",
       "      <td>...</td>\n",
       "      <td>73.365714</td>\n",
       "      <td>12.42</td>\n",
       "      <td>14.012857</td>\n",
       "      <td>2.628571</td>\n",
       "      <td>25.442857</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>29.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>19</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.142175</td>\n",
       "      <td>0.162357</td>\n",
       "      <td>0.155486</td>\n",
       "      <td>22.82</td>\n",
       "      <td>298.211429</td>\n",
       "      <td>298.442857</td>\n",
       "      <td>...</td>\n",
       "      <td>77.368571</td>\n",
       "      <td>22.82</td>\n",
       "      <td>15.372857</td>\n",
       "      <td>2.371429</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.371429</td>\n",
       "      <td>31.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>20</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>0.172967</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.170843</td>\n",
       "      <td>34.54</td>\n",
       "      <td>298.781429</td>\n",
       "      <td>298.878571</td>\n",
       "      <td>...</td>\n",
       "      <td>82.052857</td>\n",
       "      <td>34.54</td>\n",
       "      <td>16.848571</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.485714</td>\n",
       "      <td>32.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>41.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>21</td>\n",
       "      <td>0.128633</td>\n",
       "      <td>0.245067</td>\n",
       "      <td>0.227557</td>\n",
       "      <td>0.235886</td>\n",
       "      <td>15.36</td>\n",
       "      <td>298.987143</td>\n",
       "      <td>299.228571</td>\n",
       "      <td>...</td>\n",
       "      <td>80.337143</td>\n",
       "      <td>15.36</td>\n",
       "      <td>16.672857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>27.471429</td>\n",
       "      <td>6.771429</td>\n",
       "      <td>33.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>22</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>0.247340</td>\n",
       "      <td>7.52</td>\n",
       "      <td>299.518571</td>\n",
       "      <td>299.664286</td>\n",
       "      <td>...</td>\n",
       "      <td>80.460000</td>\n",
       "      <td>7.52</td>\n",
       "      <td>17.210000</td>\n",
       "      <td>3.014286</td>\n",
       "      <td>28.942857</td>\n",
       "      <td>9.371429</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  city  year  weekofyear   ndvi_ne   ndvi_nw   ndvi_se   ndvi_sw  \\\n",
       "0   sj  1990          18  0.122600  0.103725  0.198483  0.177617   \n",
       "1   sj  1990          19  0.169900  0.142175  0.162357  0.155486   \n",
       "2   sj  1990          20  0.032250  0.172967  0.157200  0.170843   \n",
       "3   sj  1990          21  0.128633  0.245067  0.227557  0.235886   \n",
       "4   sj  1990          22  0.196200  0.262200  0.251200  0.247340   \n",
       "\n",
       "   precipitation_amt_mm  reanalysis_air_temp_k  reanalysis_avg_temp_k  \\\n",
       "0                 12.42             297.572857             297.742857   \n",
       "1                 22.82             298.211429             298.442857   \n",
       "2                 34.54             298.781429             298.878571   \n",
       "3                 15.36             298.987143             299.228571   \n",
       "4                  7.52             299.518571             299.664286   \n",
       "\n",
       "      ...       reanalysis_relative_humidity_percent  \\\n",
       "0     ...                                  73.365714   \n",
       "1     ...                                  77.368571   \n",
       "2     ...                                  82.052857   \n",
       "3     ...                                  80.337143   \n",
       "4     ...                                  80.460000   \n",
       "\n",
       "   reanalysis_sat_precip_amt_mm  reanalysis_specific_humidity_g_per_kg  \\\n",
       "0                         12.42                              14.012857   \n",
       "1                         22.82                              15.372857   \n",
       "2                         34.54                              16.848571   \n",
       "3                         15.36                              16.672857   \n",
       "4                          7.52                              17.210000   \n",
       "\n",
       "   reanalysis_tdtr_k  station_avg_temp_c  station_diur_temp_rng_c  \\\n",
       "0           2.628571           25.442857                 6.900000   \n",
       "1           2.371429           26.714286                 6.371429   \n",
       "2           2.300000           26.714286                 6.485714   \n",
       "3           2.428571           27.471429                 6.771429   \n",
       "4           3.014286           28.942857                 9.371429   \n",
       "\n",
       "   station_max_temp_c  station_min_temp_c  station_precip_mm  total_cases  \n",
       "0                29.4                20.0               16.0            4  \n",
       "1                31.7                22.2                8.6            5  \n",
       "2                32.2                22.8               41.4            4  \n",
       "3                33.3                23.3                4.0            3  \n",
       "4                35.0                23.9                5.8            6  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:49:07.127937Z",
     "start_time": "2018-08-25T22:49:06.285818Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'seaborn' has no attribute 'scatterplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-af806439a522>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ndvi_ne'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'total_cases'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'seaborn' has no attribute 'scatterplot'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(data=train_data, x='ndvi_ne', y='total_cases', hue='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:35:22.800379Z",
     "start_time": "2018-08-25T22:35:22.787672Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:49:07.348401Z",
     "start_time": "2018-08-25T22:49:07.134359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Training\n",
      "Shapes before transformation\n",
      "Train :  (1456, 24)\n",
      "Test :  (416, 24)\n",
      "Train + Test :  (1872, 24)\n",
      "Shapes after transformation\n",
      "Train :  (1456, 25)\n",
      "Test :  (416, 24)\n"
     ]
    }
   ],
   "source": [
    "def pre_process_train_test_data(train, test, label_var, exclude_scaling):\n",
    "    labels = np.ravel(train[label_var])\n",
    "    train = pd.get_dummies(train.drop(label_var, axis=1))\n",
    "    test = pd.get_dummies(test)\n",
    "\n",
    "    # match test set and training set columns\n",
    "    to_drop = np.setdiff1d(test.columns, train.columns)\n",
    "    to_add = np.setdiff1d(train.columns, test.columns)\n",
    "\n",
    "    test.drop(to_drop, axis=1, inplace=True)\n",
    "    test = test.assign(**{c: 0 for c in to_add})\n",
    "\n",
    "    train.fillna(0, inplace=True)\n",
    "    test.fillna(0, inplace=True)\n",
    "\n",
    "    test_indices = test.index\n",
    "    train_indices = train.index\n",
    "    train_test = pd.concat([train, test])\n",
    "    train_test.sort_values(['year', 'weekofyear'], inplace=True)\n",
    "    train_test.interpolate(method='linear', inplace=True)\n",
    "\n",
    "    print(\"Shapes before transformation\")\n",
    "    print(\"Train : \", train.shape)\n",
    "    print(\"Test : \", test.shape)\n",
    "    print(\"Train + Test : \", train_test.shape)\n",
    "\n",
    "    numeric_vals = train_test.select_dtypes(include=['int64', 'float64'])\n",
    "    numeric_vals = numeric_vals.loc[:, [x for x in list(numeric_vals.columns.values) if x not in exclude_scaling]]\n",
    "    scaler = StandardScaler()\n",
    "    train_test[numeric_vals.columns] = scaler.fit_transform(numeric_vals)\n",
    "\n",
    "    train = train_test.loc[train_indices, :]\n",
    "    test = train_test.loc[test_indices, :]\n",
    "\n",
    "    train[label_var] = labels\n",
    "\n",
    "    print(\"Shapes after transformation\")\n",
    "    print(\"Train : \", train.shape)\n",
    "    print(\"Test : \",  test.shape)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "print(\"Preprocessing Training\")\n",
    "label_var = 'total_cases'\n",
    "exclude_scaling = ['year', 'weekofyear']\n",
    "a_train, a_test = pre_process_train_test_data(train_data, X_test, label_var, exclude_scaling)\n",
    "X_train = a_train.drop(label_var, axis=1)\n",
    "y_train = np.ravel(a_train[label_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:50:57.261140Z",
     "start_time": "2018-08-25T22:50:57.246372Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:49:07.407685Z",
     "start_time": "2018-08-25T22:49:07.399018Z"
    }
   },
   "outputs": [],
   "source": [
    "## restructure train data\n",
    "all_train_data = {'features': X_train,\n",
    "                  'labels': y_train}\n",
    "\n",
    "## restructure test data\n",
    "all_test_data = {'features': X_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation -- Tune Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:52:03.564517Z",
     "start_time": "2018-08-25T22:51:44.221999Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n",
      "29 operators have been imported by TPOT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "A pipeline has not yet been optimized. Please call fit() first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda2\\envs\\py37\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    617\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m                     \u001b[0mper_generation_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_periodic_pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m                 )\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py37\\lib\\site-packages\\tpot\\gp_deap.py\u001b[0m in \u001b[0;36meaMuPlusLambda\u001b[1;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, pbar, stats, halloffame, verbose, per_generation_function)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[0mfitnesses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py37\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36m_evaluate_individuals\u001b[1;34m(self, individuals, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m   1161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop_by_max_time_mins\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1162\u001b[1;33m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial_wrapped_cross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msklearn_pipeline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msklearn_pipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1163\u001b[0m                 \u001b[0mresult_score_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_score_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py37\\lib\\site-packages\\stopit\\utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m                     \u001b[1;31m# ``result`` may not be assigned below in case of timeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py37\\lib\\site-packages\\tpot\\gp_deap.py\u001b[0m in \u001b[0;36m_wrapped_cross_val_score\u001b[1;34m(sklearn_pipeline, features, target, cv, scoring_function, sample_weight, groups)\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msklearn_pipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m     \u001b[0mcv_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msklearn_pipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1203\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1204\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1205\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1545\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1546\u001b[1;33m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[0;32m   1547\u001b[0m                              \u001b[1;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-40d4b170b7cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m                                         \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                         generations=30, max_eval_time_mins=10)\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mpipeline_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mpipeline_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tpot_best_model_pipeline.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py37\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    648\u001b[0m                     \u001b[1;31m# raise the exception if it's our last attempt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mattempts\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py37\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    639\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_top_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m                     \u001b[1;31m# Delete the temporary cache before exiting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py37\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36m_update_top_pipeline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    713\u001b[0m             \u001b[1;31m# If user passes CTRL+C in initial generation, self._pareto_front (halloffame) shoule be not updated yet.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m             \u001b[1;31m# need raise RuntimeError because no pipeline has been optimized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'A pipeline has not yet been optimized. Please call fit() first.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: A pipeline has not yet been optimized. Please call fit() first."
     ]
    }
   ],
   "source": [
    "tune_params = 1\n",
    "if tune_params > 0:\n",
    "    bestParams = []\n",
    "    cv = StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=42)\n",
    "    X = all_train_data['features'].values.astype(np.float32)\n",
    "    y = all_train_data['labels'].astype(np.int16)\n",
    "    pipeline_optimizer = TPOTClassifier(scoring='neg_log_loss', cv=cv, \n",
    "                                        periodic_checkpoint_folder='../data/tpot_best_models/',\n",
    "                                        n_jobs=1, random_state=42, verbosity=3, memory='auto',\n",
    "                                        generations=30, max_eval_time_mins=10)\n",
    "    pipeline_optimizer.fit(X, y)\n",
    "    pipeline_optimizer.export('tpot_best_model_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:49:08.013053Z",
     "start_time": "2018-08-25T22:49:01.364Z"
    }
   },
   "outputs": [],
   "source": [
    "# trained_models = {}\n",
    "\n",
    "# ## Train Model A\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# trained_models['A'] = GradientBoostingClassifier(learning_rate=0.1, max_depth=7, \n",
    "#                                                  max_features=0.5, min_samples_leaf=14, \n",
    "#                                                  min_samples_split=20, n_estimators=100, subsample=0.6)\n",
    "# trained_models['A'].fit(all_train_data['A']['features'], all_train_data['A']['labels'])\n",
    "\n",
    "# ## Train Model B\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "# from sklearn.pipeline import make_pipeline, make_union\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from copy import copy\n",
    "\n",
    "# trained_models['B'] = make_pipeline(make_union(FunctionTransformer(copy), \n",
    "#                                                FunctionTransformer(copy)),\n",
    "#                                     LogisticRegression(C=0.01, dual=True, penalty=\"l2\"))\n",
    "\n",
    "# trained_models['B'].fit(all_train_data['B']['features'], all_train_data['B']['labels'])\n",
    "\n",
    "# ## Train Model C\n",
    "# from sklearn.naive_bayes import BernoulliNB\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from tpot.builtins import StackingEstimator\n",
    "\n",
    "# trained_models['C'] = make_pipeline(\n",
    "#     make_union(FunctionTransformer(copy), \n",
    "#                StackingEstimator(estimator=BernoulliNB(alpha=1.0, fit_prior=False))),\n",
    "#     RandomForestClassifier(bootstrap=True, criterion=\"entropy\", \n",
    "#                            max_features=0.8, min_samples_leaf=6, \n",
    "#                            min_samples_split=19, n_estimators=100))\n",
    "\n",
    "# trained_models['C'].fit(all_train_data['C']['features'], all_train_data['C']['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:49:08.014942Z",
     "start_time": "2018-08-25T22:49:01.385Z"
    }
   },
   "outputs": [],
   "source": [
    "# # ## Predict\n",
    "# predictions = {}\n",
    "# for grp in all_train_data:\n",
    "#     predictions[grp] = trained_models[grp].predict_proba(all_test_data[grp]['features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate and Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T22:49:08.032495Z",
     "start_time": "2018-08-25T22:49:01.391Z"
    }
   },
   "outputs": [],
   "source": [
    "# # convert preds to data frames\n",
    "# predictionsDF = {}\n",
    "# for grp in all_train_data:\n",
    "#     predictionsDF[grp] = make_country_sub(predictions[grp], all_test_data[grp]['features'], grp)\n",
    "\n",
    "# submission = []\n",
    "# submission = pd.concat([predictionsDF['A'], predictionsDF['B'], predictionsDF['C']])\n",
    "\n",
    "# ## Submission Format\n",
    "# submission.to_csv('../data/my_submission.csv')\n",
    "\n",
    "# # no parameters unless we have a read_csv kwargs file\n",
    "# v = DrivenDataValidator()\n",
    "\n",
    "# if v.is_valid('../data/submission_format.csv', '../data/my_submission.csv'):\n",
    "#     print \"I am awesome.\"\n",
    "# else:\n",
    "#     print \"I am not so cool.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
